\chapter{Code Generation}

This chapter details on what is arguably the ultimate goal of the compiler: the code generation process.
Using the type-checked abstract syntax tree, we generate an immediate representation.
In turn, that immediate representation, or IR, is then translated into assembly.

This chapter details the process from generating the IR to assembly code for the Simple Stack Machine, SSM.


\section{Intermediate Representation}

Since the end of the previous chapter, we have been able to verify whether a program is valid type-wise.
The program is still represented by the same AST we started out with during the parser phase, however.
To ease the assembly generation process, we first translated the AST to a data structure that looks more like actual assembly.

To start off, we require a few boilerplate data types that represent registers, labels, and immediates:

%\begin{listing}
\begin{minted}[frame=single]{Haskell}
data SplPseudoRegister
  -- simple register
  = Reg String
  -- ex: TupleLeft (TupleRight (Reg myTuple))
  | TupleFst SplPseudoRegister
  | TupleSnd SplPseudoRegister
  -- list value and pointer to tail
  | ListHd SplPseudoRegister
  | ListTl SplPseudoRegister
  -- ex: ListHd (TupleFst (Reg myTupleWithAListAndField))
  -- for tail empty
  | EmptyList
  deriving (Show, Eq)

type SplLabel = String

data SplImm = SplImmInt Integer | SplImmBool Bool | SplImmChar Char
  deriving Show
\end{minted}
%\caption{Definitions for pseudo-registers, labels and immediates.}
%\end{listing}

As registers are yet to be allocated in this phase, we introduce a pseudo-register data type.
We have opted to represent fields as encapsulated pseudo-registers, as they closely relate to load and store operations.
Furthermore, we introduce an \spl{EmptyList} register that will effectively yield a null-pointer.

Note that we will not be allocating many registers for the Simple Stack Machine (SSM), as most of the SSM's instructions operate directly on the stack.
However, as we will see in the next chapter, they are required to generate code for real hardware.

With these boilerplate types, we can start translating the program.
We will be using the following data type to represent it:

\begin{listing}
\begin{minted}[frame=single]{Haskell}
data SplInstruction
  = SplFunction SplLabel [SplPseudoRegister] SplIR
  -- if   unique   cond              Then  Else
  | SplIf SplLabel SplPseudoRegister SplIR SplIR
  -- while   unique   cond                       body
  | SplWhile SplLabel (SplIR, SplPseudoRegister) SplIR
  -- binop             op                dest
  | SplBinaryOperation SplBinaryOperator SplPseudoRegister
                    -- a                 b
                       SplPseudoRegister SplPseudoRegister
  -- unary op         op               dest
  | SplUnaryOperation SplUnaryOperator SplPseudoRegister
                   -- src
                      SplPseudoRegister
  | SplRet (Maybe SplPseudoRegister)
  -- mov   dest              src
  | SplMov SplPseudoRegister SplPseudoRegister
  | SplMovImm SplPseudoRegister SplImm
  | SplCall SplLabel (Maybe SplPseudoRegister)
            [SplPseudoRegister]
  -- make a new tuple     name           left
  | SplTupleConstr SplPseudoRegister SplPseudoRegister
                -- right
                   SplPseudoRegister

type SplIR = [SplInstruction]
\end{minted}
\caption{Definitions for instructions in IR.}
\end{listing}

With this, we can represent (sections of) the program as a list of \spl{SplInstruction}s, or \spl{SplIR} for short.
On first glance, the \spl{SplInstruction} data type still looks relatively high-level, of course.
However, looks can be deceiving.

The most notable important changes are found in the way expressions are transformed.
Expressive assignment statements are unrolled into multiple \spl{SplBinaryOperation}s and \spl{SplUnaryOperation}s as needed.
Note that all variable identifiers are replaced with pseudo-registers of the same name.
Intermediaries generated while unrolling are assigned to a pseudo-register with a unique name from a central pool.

In order to handle tuples efficiently tuples further down the line, we introduce an \spl{SplTupleConstr} construct.
This ensures the pair of (pseudo-)registers is kept together when allocating memory.

Finally, \spl{SplMov} and \spl{SplMovImm} are introduced to generate loads from registers and immediates, respectively.
These may, for example, be used to place arguments on the stack, before calling a function with an \spl{SplCall}.


\section{Simple Stack Machine}

The first compiler front-end we made was one for the Simple Stack Machine, or SSM \cite{SSM}, which in itself is simulated using Java.
As its name suggests, an interesting property of the SSM is that most of its operations work on the stack, rather than registers.
Hence, we made the choice not to allocate registers for variables, as they would need to be pushed on the stack anyway in order to do an operation on them.

Aside from the normal stack, the SSM also offers heap allocation.
In essence, this is another stack.
However, unlike the normal stack, we make use of the heap to allocate lists and tuples.
At the time of writing, no garbage collection has been implemented.
Hence, an element of a list or tuple remains allocated, even if it is no longer referred to from the stack.

Per convention, all variables on the stack are exactly the size of one word, 32-bits.
This includes addresses, booleans, characters, and integers.
Characters are represented as their ordinal UTF-16 values, integers use two's complement, and booleans are \texttt{0} for \texttt{False} and \texttt{1} for \texttt{True}.


\subsection{Global Variables}

To accomodate global variables, we reserve a frame on the stack that is exactly the total size of all global variables.

This is done as follows.
At the start of an SSM program, we push the current stack pointer to register 5.
We then push each of the global variables to the stack, evaluating its expressions as needed.

While generating assembly code, a virtual stack pointer keeps track of the expected position of the global's value using a zero-based offset from the address in register 5.
Hence, for the rest of the program's execution, register 5's sole purpose will be to help load and store global variables from their tracked offset.

Note that, as mentioned in the previous section, lists and tuples live on the heap.
Hence, if a global variable is of either type, only a pointer (i.e. an address) will be allocated.


\subsection{Calling Convention}

As the SSM works primarily with the stack, we do not need to generate any spilling code for general-purpose registers.
Hence, calling a function is done by loading all its arguments onto a new stack frame, followed directly by the BSR (Branch SubRoutine) call to the function in question.

Per convention, we use register 4 as a \emph{result register}.
Hence, after a function returns, we load the value of this register onto the stack.
There are two exceptions to this: the function can be a void type, or called as a function statement.
In either case, no result is saved; therefore no code is generated either.

Like global variables before, lists and tuples for arguments or local variables live on the heap as well.
Hence, if a global variable is of either type, only a pointer (i.e. an address) will be passed to the function.


\section{Reflection}

In retrospect, the intermediate representation we chose was \emph{too} simplified.
While translating the program into instructions that more closely resembled that of a processor did make it easy to generate assembly instructions, the loss of context aso made it much more difficult to retroactively debug what a (pseudo-)register represented.

Futhermore, unrolling expressions meant the generation of temporaries, which are then treated as any other variable by the code generator, generating many consecutive \texttt{LDC} and {LDL} invocations.

Moreover, temporaries are not deleted in a timely manner.
For functions, we did not find this to be too much of a problem, as they will be cleaned up at the end of a function's scope.
However, global variables are initialised at the start of the program.
Hence, their temporaries will pollute the stack during its entire run.

Finally, we experienced difficulties finishing the code generator within the time allotted in the course's schedule.
We found that, given another week, we were able to finish the entire SSM front-end.
Regrettably, that meant we were unable to finish it completely for the presentation sessions.
