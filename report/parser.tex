\chapter{Parser}
\todo[inline]{Dibs Aaron}

\section{Changes to the grammar}

In order to successfully implement an $LL$ parser, we first needed to eleminate left-recursive elements from the original SPL grammar.
The elements in question were located in the \textsf{FArgs}, \textsf{Field}, and \textsf{Exp} rules.

For a complete overview of the implemented grammar, please see Appendix \ref{ch:grammar}.
This section will detail the the changes made to the original grammar.

\subsection{Removing left recursion}

The first two rules, \textsf{FArgs} and \textsf{Field}, were trivial to change.
Hence, the transformed rules read as follows:

\begin{framed}
	\begin{grammar}
	<FArgs> ::= <id> [ `,' <FArgs> ]

	<Field> ::= [ `.' (`hd' | `tl' | `fst' | `snd') <Field> ]
	\end{grammar}
\end{framed}

However, the \textsf{Exp} field required more work to transform its binary operations.

\subsection{Transforming binary operations}

The original grammar defined binary operations within the \textsf{Exp} rule as a combination of two expressions and an operator: \textsf{Exp} \textsf{Op2} \textsf{Exp}.
We dealt with the left recursion here by unrolling the binary expressions, taking their operator precedence into account:

\begin{framed}
	\begin{grammar}
		<Exp> ::= <Exp2> `:' <Exp> | <Exp2>

		<Exp2> ::= <Exp3> `\textbar\textbar' <Exp2> | <Exp3>

		<Exp3> ::= <Exp4> `\&\&' <Exp3> | <Exp4>

		<Exp4> ::= <Exp5> (`==' | `\textless' | `\textgreater' | `\textless=' | `\textgreater=' | `!=') <Exp4> | <Exp5>

		<Exp5> ::= <Exp6> (`+' | `-') <Exp5> | <Exp6>

		<Exp6> ::= <ExpW> (`*' | `/' | `\%') <Exp6> | <ExpW>

		<ExpW> ::= <id> <Field>
			\alt <Op1> <Exp>
			\alt <int>
			\alt <char>
			\alt `False' | `True'
			\alt `(' <Exp> `)'
			\alt <FunCall>
			\alt `[]'
			\alt `(' <Exp> `,' <Exp> `)'
	\end{grammar}
\end{framed}

The \textsf{Exp} rule now starts with an attempt to read a cons operation.
If this fails, we fall through to the logical or operation, et cetera, until we ultimately reach what we call `weak' expressions, \textsf{ExpW}.

Clearly, these new rules have removed left recursion, while retaining expressiveness of expressions.
As an added bonus, the order of operations is now more clearly defined.

\subsection{Additional changes}

The \textsf{FunType} rule was modified to make its arrow optional for functions without any arguments:

\begin{framed}
	\begin{grammar}
	<FunType> ::= [ <FTypes> `\textrightarrow' ] <RetType>
	\end{grammar}
\end{framed}

\section{Parser Combinators}

One of our main reasons for choosing Haskell was the prospect of being able to work with parser combinators.
Combined with Haskell's powerful type system, these combinators make processing a source file into an algebraic data type, in this case an abstract syntax tree (AST), particularly easy.
For a complete overview of the AST, please see Appendix \ref{ch:ast}.

Rather than implementing combinators ourselves, we opted to use the popular MegaParsec library.
This is a fork of the popular, but no longer maintained, Parsec library.
Added features include full Unicode support, as well as better testing equipment for use with HSpec.

In the rest of this section, we will explain the workings of these combinators by example.

Consider the data structure in listing \ref{lst:splfield_ast}, defining the \textsf{Field} component of our grammar:

\begin{listing}
\begin{minted}[frame=single]{haskell}
data SplField = SplFieldHd  SplField
              | SplFieldTl  SplField
              | SplFieldFst SplField
              | SplFieldSnd SplField
              | SplFieldNone
\end{minted}
\caption{Definition of SplField in SplAST.hs.}
\label{lst:splfield_ast}
\end{listing}

To parse such a field, the \spl{field} function is invoked after reading an identifier.
Listing \ref{lst:splfield_parser} shows the code for this function:

\begin{listing}
\begin{minted}[frame=single]{haskell}
field :: Parser SplField
field = char '.' *> (
            readKw "hd"  *> (SplFieldHd  <$> field)
        <|> readKw "tl"  *> (SplFieldTl  <$> field)
        <|> readKw "fst" *> (SplFieldFst <$> field)
        <|> readKw "snd" *> (SplFieldSnd <$> field)
    ) <* sc
    <|> return SplFieldNone
    where
        readKw :: String -> Parser ()
        readKw w = string w *> notFollowedBy alphaNumChar
\end{minted}
\caption{Definition of the \texttt{field} parser in \texttt{SplParser.hs}.}
\label{lst:splfield_parser}
\end{listing}

From quickly reading the funtion, it becomes apparent that it covers all five possible fields: head, tail, first, and second.
Three helper functions are used:
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\item \texttt{char}, which tries to read one Unicode character.
	\item \texttt{sc}, which greedily reads and discards white\textbf{s}paces and \textbf{c}omments.
	\item \texttt{readKw}, which reads a particular \textbf{k}ey\textbf{w}ord.
\end{itemize}

The \spl{field} function has two main branches.
At the start, we try to read a `.' to indicate a field.
If no period can be read, the \spl{SplFieldNone} token is yielded.

Otherwise, we enter a branch with the \texttt{*>} combinator.
In the branch, we try to read either of four keywords, followed by another word using the \texttt{<\$>} binding operator.
Note that the \texttt{<|>} combinator facilitates in branching.

Because we used the \texttt{*>} combinator, the result of the branch is yieled as the result of the outer block. If no result is obtained, a parse error is generated.

Finally, we consume any remaining whitespace or comments using the aforementioned \spl{sc} helper function.

Note that, at this stage, we do not verify whether \spl{hd} or \spl{tl} is applied to a list, nor whether \spl{fst} or \spl{snd} is applied to a tuple.
This is left for the type inferencer, which the next chapter will cover.

\section{Testing}

As previously mentioned, a strict typing system like Haskell's allows us to easily transform source code into an algebric data type.
This allows us to test the parser relatively easily with the use of Haskell's HSpec testing system.

As an example, we will revisit the field parser discussed in the previous section. Consider the specifications in listing \ref{lst:splfield_spec}:

\begin{listing}
\begin{minted}[frame=single]{haskell}
spec :: Spec
spec = do
  // ...
  describe "expressions" $ do
  // ...
    it "parses identifiers" $
      parseExpr "example" `shouldParse`
        (SplIdentifierExpr "example" SplFieldNone)

    it "parses identifiers with fields" $
      parseExpr "example.hd" `shouldParse`
        (SplIdentifierExpr "example" (SplFieldHd (SplFieldNone)))

    it "parses identifiers with nested fields" $
      parseExpr "example.hd.tl" `shouldParse`
        (SplIdentifierExpr "example"
          (SplFieldHd $ SplFieldTl $ SplFieldNone))
  // ...
\end{minted}
\caption{Tests for the \texttt{field} parser in \texttt{ParserSpec.hs}.}
\label{lst:splfield_spec}
\end{listing}

The specification denotes the expected parse tree for three expressions: the first one having no field, the second one with one field, and the last one having an extra nested field.

Our full AST data type is covered by HSpec specifications.
Hence, any changes in the parser code can immediately be tested for adverse effects.
Indeed, if a bug is found in the parser, another test can be added to prevent said bug from re-occurring as a regression.

\section{Pretty Printing}

While Haskell strict typing system like allows us to easily transform source code into an algebric data type, the reverse is also possible.
Although Haskell allows printing data types easily through its \spl{Show} classes, these are not context sensitive.
Hence, through these it is more difficult to print nested blocks.
To achieve this, we make use of \emph{printer combinators}.
We opted to use Haskell's built-in \texttt{Text.PrettyPrint} library.

For illustrative purposes, we list the code used to print a \textsf{While} block in listing \ref{lst:splprettyprinter}.

\begin{listing}
\begin{minted}[frame=single]{haskell}
  printStmt :: SplStmt -> Doc
  // ...
  printStmt (SplWhileStmt cond stmts) =
        text "while"
    <+> parens (printExpr cond)
    <+> lbrace
    $+$ (nest 4 $ printStmts stmts)
    $+$ rbrace
\end{minted}
\caption{Pretty printer for \texttt{SplWhileStmt} in \texttt{SplPrettyPrinter.hs}.}
\label{lst:splprettyprinter}
\end{listing}

In the listing, two notable combinators are used: \texttt{<+>} and \texttt{\$+\$}. The former combines a \spl{Doc} with a space, collapsing the spaces into one if two occur side-by-side. The latter does the same, but with line endings instead of spaces.

Most of the helper functions have self-explanatory names.
\texttt{parens} wraps a given \spl{Doc} between parentheses.
\texttt{lbrace} and \texttt{rbrace} respectively insert a left and right brace.
Note that a wrapping \texttt{braces} function exists as well, but due to currying we cannot use it in combination with the \texttt{nest} function.

\section{Reflection}

We were pleasantly surprised with the combinators' versatility.
Most notably for their use in the parsing process, but also for doing the reverse in the pretty printer.

Looking back, there are definite points of improvements for our parser and its data structures, however.

When our project consisted of merely a parser, it was fine to rely on MegaParsec's built-in error handler.
With this in mind, we did not consider needing to store additional information in the AST, such as the original position in the source code, or indeed the original token.
As our compiler progressed, in particular the type inferencer, it became apparent that this information was now missing.
However, as the AST was in use in some form by the majority of functions, it also became clear that adding this information at this stage would be very time consuming.
This limitation culminated in us not being able to store inferred type information in the AST without compromise

Should the need arise to implement another compiler in Haskell, we take with us the knowledge that we should use a more abstract data type for our AST.
While retaining the labeled tree structure, we could make use of records to store additional information in an extensible manner.
Indeed, when the need arises, the record structure in question can then be extended with e.g. type annotations.
